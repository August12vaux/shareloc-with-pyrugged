{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute DSM step by step\n",
    "\n",
    "This notebook explains how to run step by step DSM computation with CARS, starting from the prepare step output folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook parameters\n",
    "\n",
    "Those parameters need to be set before running the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the cars folder\n",
    "cars_home = \"/work/OT/siaa/3D/Development/guinetj/cars-hal/cars/\"\n",
    "# Path to the directory containing the content.json file of the prepare step output\n",
    "content_dir = \"/work/OT/siaa/3D/Temporary/guinetj/Shareloc/Data/couple_paca_roi1/\"\n",
    "# ROI to process (roi_file = path to a vector file, raster file or roi_bbox=bounding box), as expected by cars_cli\n",
    "# Use one or the other (roi_file will have precedence if not None)\n",
    "roi_file = \"/work/OT/siaa/3D/Temporary/guinetj/Shareloc/Data/couple_paca_roi1/envelopes_intersection.gpkg\" # Put roi_file=None to use roi_bbox\n",
    "roi_bbox = [\"xmin\", \"ymin\", \"xmax\", \"ymax\"] # Use 4 floats value\n",
    "# Path to output dir where to save figures and data\n",
    "output_dir = \"/work/OT/siaa/3D/Temporary/guinetj/Shareloc/Data/couple_paca_roi1/out/\"\n",
    "\n",
    "import os\n",
    "# path to shareloc test data\n",
    "os.environ[\"TESTPATH\"] = \"/work/OT/siqi/guinetj/ShareLoc/shareloc/valid\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test shareloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/work/OT/siqi/guinetj/ShareLoc/shareloc/valid/ellipsoide/P1BP--2017092838284574CP/grilles_gld_xH/P1BP--2017092838284574CP_H1.hd'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ced07830ec3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdata_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"TESTPATH\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_scene_left\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mgld_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_folder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'grilles_gld_xH/{}_H1.hd'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_scene_left\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mgri_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgld_left\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdata_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"TESTPATH\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_scene_right\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/OT/siqi/guinetj/ShareLoc/shareloc/shareloc/grid.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, grid_filename, grid_format)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrowmax\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolmax\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'multi H grid'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/OT/siqi/guinetj/ShareLoc/shareloc/shareloc/grid.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mnom_hd\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'1.hd'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mdico_hd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_bsq_hd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnom_hd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdico_a_lire\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdico_hd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/work/OT/siqi/guinetj/ShareLoc/shareloc/shareloc/readwrite.py\u001b[0m in \u001b[0;36mread_bsq_hd\u001b[0;34m(fic_hd, tag)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \"\"\"\n\u001b[1;32m     87\u001b[0m     \u001b[0mdico_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfic_hd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mtxt_header\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/work/OT/siqi/guinetj/ShareLoc/shareloc/valid/ellipsoide/P1BP--2017092838284574CP/grilles_gld_xH/P1BP--2017092838284574CP_H1.hd'"
     ]
    }
   ],
   "source": [
    "from shareloc.grid import grid\n",
    "id_scene_left = \"P1BP--2017092838284574CP\"\n",
    "id_scene_right = \"P1BP--2017092838319324CP\"\n",
    "datum = 'ellipsoide'\n",
    "\n",
    "data_folder = os.path.join(os.environ[\"TESTPATH\"], datum, id_scene_left)\n",
    "gld_left = os.path.join(data_folder,'grilles_gld_xH/{}_H1.hd'.format(id_scene_left))\n",
    "gri_left = grid(gld_left)\n",
    "\n",
    "data_folder = os.path.join(os.environ[\"TESTPATH\"], datum, id_scene_right)\n",
    "gld_right = os.path.join(data_folder,'grilles_gld_xH/{}_H1.hd'.format(id_scene_right))\n",
    "gri_right = grid(gld_right)\n",
    "\n",
    "grid_left_filename = os.path.join(content_dir, \"left_epipolar_grid.tif\")\n",
    "grid_right_filename = os.path.join(content_dir, \"right_epipolar_grid.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Trick to override cars version\n",
    "import sys\n",
    "sys.path = [cars_home] + sys.path\n",
    "\n",
    "import math\n",
    "os.environ['OTB_APPLICATION_PATH'] = os.path.join(cars_home,'build','lib','otb','applications')+':'+os.environ['OTB_APPLICATION_PATH']\n",
    "###\n",
    "# Silent OTB info logs\n",
    "os.environ['OTB_LOGGER_LEVEL']='WARNING'\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=UserWarning)\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.colors import LightSource\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from cars import stereo, parameters, configuration_correlator, rasterization, utils, projection, tiling, filtering\n",
    "from bin.cars_cli import parse_roi_file\n",
    "import pandora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First step is to read the content file from the prepare step, and to retrieve the disparity range. Note that disparity range can be changed here for experimentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = parameters.read_preprocessing_content_file(os.path.join(content_dir,'content.json'))\n",
    "disp_min = int(math.floor(conf['preprocessing']['output']['minimum_disparity']))\n",
    "disp_max = int(math.ceil(conf['preprocessing']['output']['maximum_disparity']))\n",
    "print(disp_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to set up a configuration for pandora, the disparity estimation algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_config = configuration_correlator.configure_correlator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the Region Of Interest to Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to define the region of interest that will be processed by the notebook. For that, use `roi_file` ( a vector or a raster file) or `roi_bbox` (four float array)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if roi_file is not None:\n",
    "    bounds, stop_now = parse_roi_file(roi_file, stop_now=True)\n",
    "else: \n",
    "    bounds = (roi_bbox, None)\n",
    "print(\"Bounds: {}, EPSG={}\".format(bounds[0], bounds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to compute the corresponding epipolar region:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epipolar_region = stereo.transform_terrain_region_to_epipolar(bounds[0], conf, bounds[1], disp_min, disp_max)\n",
    "print(\"Corresponding epipolar region: {} (size: {} x {} pixels)\".format(epipolar_region, epipolar_region[2]-epipolar_region[0], epipolar_region[3]-epipolar_region[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stereo-rectify images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before rectifying the images, we need to compute the margins needed by the disparity estimation algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "margins = pandora.marge.get_margins(disp_min, disp_max, corr_config)\n",
    "margins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can call the images rectification function. It will return 3 datasets, respectively for the left image, right image and left color image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_dataset, right_dataset, left_color_dataset = stereo.epipolar_rectify_images(conf, epipolar_region, margins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets display the left and right images with their masks, and see if epipolar geometry is ok with an horizontal red line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_size = 15\n",
    "clip_percent = 5\n",
    "vmin_left = np.percentile(left_dataset.im,clip_percent)\n",
    "vmax_left = np.percentile(left_dataset.im,100-clip_percent)\n",
    "vmin_right = np.percentile(right_dataset.im,clip_percent)\n",
    "vmax_right = np.percentile(right_dataset.im,100-clip_percent)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(fig_size, 1.05 * fig_size / 2), subplot_kw={'aspect': 1})\n",
    "axes[0].set_title(\"Left image\")\n",
    "axes[0].imshow(left_dataset.im, cmap=\"gray\", interpolation='spline36', vmin=vmin_left, vmax=vmax_left)\n",
    "axes[0].imshow(left_dataset.msk.where(left_dataset.msk !=0), cmap='tab10', alpha=0.5)\n",
    "axes[0].axhline(len(left_dataset.row)/2., color='red')\n",
    "axes[1].set_title(\"Right image\")\n",
    "axes[1].imshow(right_dataset[\"im\"], cmap=\"gray\", interpolation='spline36', vmin=vmin_right, vmax=vmax_right)\n",
    "axes[1].imshow(right_dataset.msk.where(right_dataset.msk !=0), cmap='tab10', alpha=0.5)\n",
    "axes[1].axhline(len(right_dataset.row)/2., color='red')\n",
    "fig.tight_layout()\n",
    "fig.savefig(os.path.join(output_dir,'epipolar_images.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Disparity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have stereo-rectified images, we can compute the disparity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp = stereo.compute_disparity(left_dataset, right_dataset, corr_config, disp_min, disp_max, verbose = True, use_sec_disp=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We crop out margins, since we do not need them anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_dataset, tmp = xr.align(left_dataset,disp['ref'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triangulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we estimated the disparity, we can triangulate it to get WGS84 3D points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "now = time.time()\n",
    "cloud = stereo.triangulate(conf, disp['ref'])\n",
    "elapsed = time.time() - now\n",
    "print(\"elapsed time {}\".format(elapsed))\n",
    "cloud['ref'].to_netcdf(os.path.join(output_dir, \"cloud_WGS84.nc\"))\n",
    "cloud['ref'] = projection.points_cloud_conversion_dataset(cloud['ref'], 4978)\n",
    "cloud['ref'].to_netcdf(os.path.join(output_dir, \"cloud_ECEF.nc\"))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triangulation shareloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shareloc.triangulation.triangulation import epipolar_triangulation\n",
    "\n",
    "\n",
    "now = time.time()\n",
    "point_ecef, point_wgs84, residuals = epipolar_triangulation(disp['ref'], None, 'disp', gri_left, gri_right, grid_left_filename,\n",
    "                                                   grid_right_filename, residues = True)\n",
    "elapsed = time.time() - now\n",
    "print(\"elapsed time {}\".format(elapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_shape = disp['ref'].disp.values.shape\n",
    "array_epi_ecef = point_ecef.reshape((array_shape[0], array_shape[1], 3))\n",
    "\n",
    "\n",
    "ecef_x = cloud['ref'].x.values\n",
    "ecef_y = cloud['ref'].y.values\n",
    "ecef_z = cloud['ref'].z.values\n",
    "diff_x = ecef_x - array_epi_ecef[:,:,0]\n",
    "diff_y = ecef_y - array_epi_ecef[:, :, 1]\n",
    "diff_z = ecef_z - array_epi_ecef[:, :, 2]\n",
    "\n",
    "mean_x = np.mean(diff_x)\n",
    "min_x = np.min(diff_x)\n",
    "max_x = np.max(diff_x)\n",
    "print(\" diff x {} {} {}\".format(mean_x,min_x,max_x))\n",
    "mean_y = np.mean(diff_y)\n",
    "min_y = np.min(diff_y)\n",
    "max_y = np.max(diff_y)\n",
    "print(\" diff y {} {} {}\".format(mean_y,min_y,max_y))\n",
    "mean_z = np.mean(diff_z)\n",
    "min_z= np.min(diff_z)\n",
    "max_z = np.max(diff_z)\n",
    "print(\" diff z {} {} {}\".format(mean_z,min_z,max_z)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving left, right and left color datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_dataset.to_netcdf(os.path.join(output_dir, \"left_dataset.nc\"))\n",
    "right_dataset.to_netcdf(os.path.join(output_dir, \"right_dataset.nc\"))\n",
    "left_color_dataset.to_netcdf(os.path.join(output_dir, \"left_color_dataset.nc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving disparity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disp['ref'].to_netcdf(os.path.join(output_dir, \"disparity.nc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving Shareloc augmented disparity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(disp,point_wgs84,point_ecef,residuals):\n",
    "    array_shape = disp.disp.values.shape\n",
    "    array_epi_wgs84 = point_wgs84.reshape((array_shape[0], array_shape[1], 3))\n",
    "    array_epi_ecef = point_ecef.reshape((array_shape[0], array_shape[1], 3))\n",
    "    array_residuals = residuals.reshape((array_shape[0], array_shape[1]))\n",
    "    pc_dataset = xr.Dataset({'pc_wgs84_x': (['row', 'col'], array_epi_wgs84[:, :, 0]),\n",
    "                             'pc_wgs84_y': (['row', 'col'], array_epi_wgs84[:, :, 1]),\n",
    "                             'pc_wgs84_z': (['row', 'col'], array_epi_wgs84[:, :, 2]),\n",
    "                             'pc_ecef_x': (['row', 'col'], array_epi_ecef[:, :, 0]),\n",
    "                             'pc_ecef_y': (['row', 'col'], array_epi_ecef[:, :, 1]),\n",
    "                             'pc_ecef_z': (['row', 'col'], array_epi_ecef[:, :, 2]),\n",
    "                             'residues': (['row', 'col'], array_residuals)},\n",
    "                            coords={'row': disp.coords['row'], 'col': disp.coords['col'] })\n",
    "    return pc_dataset\n",
    "\n",
    "pc_dataset = create_dataset(disp['ref'], point_wgs84, point_ecef, residuals)\n",
    "disp = xr.merge((disp['ref'], pc_dataset))\n",
    "out_disp_filename = os.path.join(output_dir, \"out_disparity_shareloc_grid.nc\")\n",
    "disp.to_netcdf(out_disp_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving triangulated cloud:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud['ref'].to_netcdf(os.path.join(output_dir, \"cloud.nc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving DSM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster.to_netcdf(os.path.join(output_dir, \"dsm.nc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save cloud in ply file format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.write_ply(os.path.join(output_dir,\"points.ply\"),cloud['ref'])\n",
    "if small_cpn_filter_params is not None or statistical_filter_params is not None:\n",
    "    utils.write_ply(os.path.join(output_dir,\"filtered_points.ply\"),filtered_points)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shareloc_cars",
   "language": "python",
   "name": "shareloc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
